### Notes

* Paper clip AI scenario. ASI - *Artificial Superintelligence* 
* A well-aligned AI will use its superpowers to save humanity by curing diseases and solving our most pressing problems; an unaligned AI could decide to wipe out all humans through any one of a number of means,Â or simply kill or enslave everyone as a by-product of its own obscure goals.
* no one really knows whether AGI is possible, or whether alignment is a real concern.

#### Artificial Ethics for Alien Minds

* Bias