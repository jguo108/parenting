### Notes

* Predictive AI technologies based on supervised learning
* a paper with the catchy title “Attention Is All You Need.” Published by Google researchers in 2017, this paper introduced a significant shift in the world of AI, particularly in how computers understand and process human language
* These new types of AI, called Large Language Models (LLMs), are still doing prediction, but rather than predicting the demand for an Amazon order, they are analyzing a piece of text and predicting the next token, which is simply a word or part of a word.
* Unlike earlier forms of AI, it is unsupervised, which means the AI doesn’t need carefully labeled data. Instead, by analyzing these examples, AI learns to recognize patterns, structures, and context in human language.
* Despite being just a predictive model, the Frontier AI models, trained on the largest datasets with the most computing power, seem to do things that their programming should not allow—a concept called *emergence*.
* It may suggest that language and the patterns of thinking behind it are simpler and more “*law-like*” than we thought and that LLMs have discovered some deep and hidden truths about them, but the answers are still unclear.
* what can AIs do, and how will they change the ways we *live*, *learn*, and *work*?